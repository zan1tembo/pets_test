import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import random_split
from torch.utils.data import Dataset
import torchvision.transforms as transforms

from PIL import Image

import argparse
import json
import logging
import os
import sys

import numpy as np
import matplotlib.pyplot as plt

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(logging.StreamHandler(sys.stdout))

# # # MODELS # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 

# 3x3 convolution
def conv3x3(in_channels, out_channels, stride=1):
    return nn.Conv2d(in_channels, out_channels, kernel_size=3,
                     stride=stride, padding=1, bias=False)
# Residual block
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = conv3x3(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(out_channels, out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out
    
# ResNet
class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=10):
        super(ResNet, self).__init__()
        self.in_channels = 16
        self.conv = conv3x3(3, 16)
        self.bn = nn.BatchNorm2d(16)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self.make_layer(block, 16, layers[0])
        self.layer2 = self.make_layer(block, 32, layers[1], 2)
        self.layer3 = self.make_layer(block, 64, layers[2], 2)
        self.avg_pool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64, num_classes)

    def make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if (stride != 1) or (self.in_channels != out_channels):
            downsample = nn.Sequential(
                conv3x3(self.in_channels, out_channels, stride=stride),
                nn.BatchNorm2d(out_channels))
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for i in range(1, blocks):
            layers.append(block(out_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.relu(out)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.avg_pool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out
            
# # # LIBRARY # # # # # # # # # # # # # # # # #

def parse_breed(fname):
    parts = fname.split('_')
    return ' '.join(parts[:-1])

def open_image(path):
    with open(path, 'rb') as f:
        img = Image.open(f)
        return img.convert('RGB')

# # # DATASET # # # # # # # # # # # # # # # # # # # # 
    
class PetsDataset(Dataset):
    def __init__(self, root, transform):
        super().__init__()
        self.root = root
        self.files = [fname for fname in os.listdir(root) if fname.endswith('.jpg')]
        self.classes = list(set(parse_breed(fname) for fname in files))
        self.transform = transform
    
    def __len__(self):
        return len(self.files)

    def __getitem__(self, i):
        fname = self.files[i]
        fpath = os.path.join(self.root, fname)
        img = self.transform(open_image(fpath))
        class_idx = self.classes.index(parse_breed(fname))
        return img, class_idx

# # # MAIN # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

def train(args):
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    DATA_DIR = '../../pets/'
    files = os.listdir(DATA_DIR)
    logger.info( files[:5] )
    logger.info( parse_breed(files[4]) )
    
    img_size = 224
    imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    transform_train = transforms.Compose([transforms.Resize(img_size),
                                          transforms.Pad(8, padding_mode='reflect'),
                                          transforms.RandomCrop(img_size),
                                          transforms.ToTensor(),
                                          transforms.Normalize(*imagenet_stats)])
    
    dataset = PetsDataset(DATA_DIR, transform_train)
    logger.info( len(dataset) )
    val_pct = 0.1
    val_size = int(val_pct * len(dataset))
    train_ds, valid_ds = random_split(dataset, [len(dataset) - val_size, val_size])
    
    batch_size = args.batch_size
    train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)
    test_loader = DataLoader(valid_ds, batch_size*2, num_workers=2, pin_memory=True)
    
    model = ResNet(ResidualBlock, [2, 2, 2], num_classes=(len(dataset.classes))).to(device)
    e = args.epochs
    curr_lr = args.lr
    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)
    
    for epoch in range(e):
        model.train()
        for i, (images, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            images, labels = images.to(device), labels.to(device)
            loss = nn.CrossEntropyLoss()(model(images), labels)
            loss.backward()
            optimizer.step()

        if ( (epoch+1) == 100 ) or ( (epoch+1) == 150 ):
            curr_lr *= 0.1
            update_lr(optimizer, curr_lr)
        if (epoch+1) % args.loss_interval == 0:
            logger.info( "Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}".format( epoch+1, e, i+1, len(train_loader), loss.item() ) )
        if (epoch+1) % args.test_interval == 0:
            results = double_test(model, test_loader, augment, device)
            logger.info( "Student: UA {:.4f}, A {:.4f}".format( results[0], results[1] ) )

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    parser.add_argument("--batch_size", type=int, default=256, metavar="N", help="training batch size")
    parser.add_argument('--epochs', type=int, default=200, metavar="N", help='number of training epochs')
    parser.add_argument('--lr', type=float, default=0.1, metavar="LR", help='learning rate')
    parser.add_argument('--momentum', type=float, default=0.9, metavar="M", help='SGD momentum')
    parser.add_argument('--weight_decay', type=float, default=5e-4, metavar="W", help='weight decay')
    parser.add_argument('--loss_interval', type=int, default=5, metavar="N", help='loss printing interval')
    parser.add_argument('--test_interval', type=int, default=25, metavar="N", help='test run interval')
    
    # Container environment
    parser.add_argument("--hosts", type=list, default=json.loads(os.environ["SM_HOSTS"]))
    parser.add_argument("--current_host", type=str, default=os.environ["SM_CURRENT_HOST"])
    parser.add_argument("--model_dir", type=str, default=os.environ["SM_MODEL_DIR"])
    parser.add_argument("--data_dir", type=str, default=os.environ["SM_CHANNEL_TRAINING"])
    parser.add_argument("--num_gpus", type=int, default=os.environ["SM_NUM_GPUS"])
    
    train(parser.parse_args())
